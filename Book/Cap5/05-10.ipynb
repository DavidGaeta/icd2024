{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d86f01-d8a0-4f38-909e-e7ebdb76df77",
   "metadata": {},
   "source": [
    "## Manifold Learning\n",
    "\n",
    "Eber David Gaytan Medina\n",
    "\n",
    "We have seen how principal component analysis (PCA) can be used in the dimensionality reduction task—reducing the number of features of a dataset while maintaining the essential relationships between the points. While PCA is flexible, fast, and easily interpretable, it does not perform so well when there are nonlinear relationships within the data; we will see some examples of these below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "\n",
    "def make_hello(N=1000, rseed=42):\n",
    "    # Make a plot with \"HELLO\" text; save as PNG\n",
    "    fig, ax = plt.subplots(figsize=(4, 1))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.4, 'HELLO', va='center', ha='center', weight='bold', size=85)\n",
    "    fig.savefig('hello.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Open this PNG and draw random points from it\n",
    "    from matplotlib.image import imread\n",
    "    data = imread('hello.png')[::-1, :, 0].T\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(4 * N, 2)\n",
    "    i, j = (X * data.shape).astype(int).T\n",
    "    mask = (data[i, j] < 1)\n",
    "    X = X[mask]\n",
    "    X[:, 0] *= (data.shape[0] / data.shape[1])\n",
    "    X = X[:N]\n",
    "    return X[np.argsort(X[:, 0])]\n",
    "\n",
    "X = make_hello(1000)\n",
    "colorize = dict(c=X[:, 0], cmap=plt.cm.get_cmap('rainbow', 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], **colorize)\n",
    "plt.axis('equal');\n",
    "\n",
    "def rotate(X, angle):\n",
    "    theta = np.deg2rad(angle)\n",
    "    R = [[np.cos(theta), np.sin(theta)],\n",
    "         [-np.sin(theta), np.cos(theta)]]\n",
    "    return np.dot(X, R)\n",
    "    \n",
    "X2 = rotate(X, 20) + 5\n",
    "plt.scatter(X2[:, 0], X2[:, 1], **colorize)\n",
    "plt.axis('equal');\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "D = pairwise_distances(X)\n",
    "D.shape\n",
    "(1000, 1000)\n",
    "As promised, for our N=1,000 points, we obtain a 1000×1000 matrix, which can be visualized as shown here:\n",
    "\n",
    "plt.imshow(D, zorder=2, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar();\n",
    "\n",
    "D2 = pairwise_distances(X2)\n",
    "np.allclose(D, D2)\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "out = model.fit_transform(D)\n",
    "plt.scatter(out[:, 0], out[:, 1], **colorize)\n",
    "plt.axis('equal');\n",
    "\n",
    "def random_projection(X, dimension=3, rseed=42):\n",
    "    assert dimension >= X.shape[1]\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    C = rng.randn(dimension, dimension)\n",
    "    e, V = np.linalg.eigh(np.dot(C, C.T))\n",
    "    return np.dot(X, V[:X.shape[1]])\n",
    "    \n",
    "X3 = random_projection(X, 3)\n",
    "X3.shape\n",
    "(1000, 3)\n",
    "Let's visualize these points to see what we're working with:\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X3[:, 0], X3[:, 1], X3[:, 2],\n",
    "             **colorize)\n",
    "ax.view_init(azim=70, elev=50)\n",
    "\n",
    "\n",
    "model = MDS(n_components=2, random_state=1)\n",
    "out3 = model.fit_transform(X3)\n",
    "plt.scatter(out3[:, 0], out3[:, 1], **colorize)\n",
    "plt.axis('equal');\n",
    "\n",
    "\n",
    "def make_hello_s_curve(X):\n",
    "    t = (X[:, 0] - 2) * 0.75 * np.pi\n",
    "    x = np.sin(t)\n",
    "    y = X[:, 1]\n",
    "    z = np.sign(t) * (np.cos(t) - 1)\n",
    "    return np.vstack((x, y, z)).T\n",
    "\n",
    "XS = make_hello_s_curve(X)\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(XS[:, 0], XS[:, 1], XS[:, 2],\n",
    "             **colorize);\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "model = MDS(n_components=2, random_state=2)\n",
    "outS = model.fit_transform(XS)\n",
    "plt.scatter(outS[:, 0], outS[:, 1], **colorize)\n",
    "plt.axis('equal');\n",
    "\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "model = LocallyLinearEmbedding(n_neighbors=100, n_components=2, method='modified',\n",
    "                               eigen_solver='dense')\n",
    "out = model.fit_transform(XS)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(out[:, 0], out[:, 1], **colorize)\n",
    "ax.set_ylim(0.15, -0.15);\n",
    "\n",
    "\n",
    "Example: Isomap on Faces\n",
    "One place manifold learning is often used is in understanding the relationship between high-dimensional data points. A common case of high-dimensional data is images: for example, a set of images with 1,000 pixels each can be thought of as a collection of points in 1,000 dimensions – the brightness of each pixel in each image defines the coordinate in that dimension.\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=30)\n",
    "faces.data.shape\n",
    "(2370, 2914)\n",
    "We have 2,370 images, each with 2,914 pixels. In other words, the images can be thought of as data points in a 2,914-dimensional space!\n",
    "\n",
    "Let's quickly visualize several of these images to see what we're working with:\n",
    "\n",
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')\n",
    "\n",
    "We would like to plot a low-dimensional embedding of the 2,914-dimensional data to learn the fundamental relationships between the images. One useful way to start is to compute a PCA, and examine the explained variance ratio, which will give us an idea of how many linear features are required to describe the data:\n",
    "\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "model = RandomizedPCA(100).fit(faces.data)\n",
    "plt.plot(np.cumsum(model.explained_variance_ratio_))\n",
    "plt.xlabel('n components')\n",
    "plt.ylabel('cumulative variance');\n",
    "\n",
    "We see that for this data, nearly 100 components are required to preserve 90% of the variance: this tells us that the data is intrinsically very high dimensional—it can't be described linearly with just a few components.\n",
    "\n",
    "When this is the case, nonlinear manifold embeddings like LLE and Isomap can be helpful. We can compute an Isomap embedding on these faces using the same pattern shown before:\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "model = Isomap(n_components=2)\n",
    "proj = model.fit_transform(faces.data)\n",
    "proj.shape\n",
    "(2370, 2)\n",
    "The output is a two-dimensional projection of all the input images. To get a better idea of what the projection tells us, let's define a function that will output image thumbnails at the locations of the projections:\n",
    "\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, cmap='gray'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    proj = model.fit_transform(data)\n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)\n",
    "Calling this function now, we see the result:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_components(faces.data,\n",
    "                model=Isomap(n_components=2),\n",
    "                images=faces.images[:, ::2, ::2])\n",
    "\n",
    "The result is interesting: the first two Isomap dimensions seem to describe global image features: the overall darkness or lightness of the image from left to right, and the general orientation of the face from bottom to top. This gives us a nice visual indication of some of the fundamental features in our data.\n",
    "\n",
    "We could then go on to classify this data (perhaps using manifold features as inputs to the classification algorithm) as we did in In-Depth: Support Vector Machines.\n",
    "\n",
    "Example: Visualizing Structure in Digits\n",
    "As another example of using manifold learning for visualization, let's take a look at the MNIST handwritten digits set. This data is similar to the digits we saw in In-Depth: Decision Trees and Random Forests, but with many more pixels per image. It can be downloaded from http://mldata.org/ with the Scikit-Learn utility:\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist.data.shape\n",
    "(70000, 784)\n",
    "This consists of 70,000 images, each with 784 pixels (i.e. the images are 28×28). As before, we can take a look at the first few images:\n",
    "\n",
    "fig, ax = plt.subplots(6, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(mnist.data[1250 * i].reshape(28, 28), cmap='gray_r')\n",
    "\n",
    "This gives us an idea of the variety of handwriting styles in the dataset.\n",
    "\n",
    "Let's compute a manifold learning projection across the data. For speed here, we'll only use 1/30 of the data, which is about ~2000 points (because of the relatively poor scaling of manifold learning, I find that a few thousand samples is a good number to start with for relatively quick exploration before moving to a full calculation):\n",
    "\n",
    "# use only 1/30 of the data: full dataset takes a long time!\n",
    "data = mnist.data[::30]\n",
    "target = mnist.target[::30]\n",
    "\n",
    "model = Isomap(n_components=2)\n",
    "proj = model.fit_transform(data)\n",
    "plt.scatter(proj[:, 0], proj[:, 1], c=target, cmap=plt.cm.get_cmap('jet', 10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);\n",
    "\n",
    "The resulting scatter plot shows some of the relationships between the data points, but is a bit crowded. We can gain more insight by looking at just a single number at a time:\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# Choose 1/4 of the \"1\" digits to project\n",
    "data = mnist.data[mnist.target == 1][::4]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "model = Isomap(n_neighbors=5, n_components=2, eigen_solver='dense')\n",
    "plot_components(data, model, images=data.reshape((-1, 28, 28)),\n",
    "                ax=ax, thumb_frac=0.05, cmap='gray_r')\n",
    "\n",
    "The result gives you an idea of the variety of forms that the number \"1\" can take within the dataset. The data lies along a broad curve in the projected space, which appears to trace the orientation of the digit. As you move up the plot, you find ones that have hats and/or bases, though these are very sparse within the dataset. The projection lets us identify outliers that have data issues: for example, pieces of the neighboring digits that snuck into the extracted images.\n",
    "\n",
    "Now, this in itself may not be useful for the task of classifying digits, but it does help us get an understanding of the data, and may give us ideas about how to move forward, such as how we might want to preprocess the data before building a classification pipeline.\n",
    "\n",
    "< In Depth: Principal Component Analysis | Contents | In Depth: k-Means Clustering >\n",
    "\n",
    "Open in Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

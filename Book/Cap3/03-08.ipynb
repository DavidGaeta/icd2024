{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d86f01-d8a0-4f38-909e-e7ebdb76df77",
   "metadata": {},
   "source": [
    "## Aggregation and Grouping\n",
    "Eber David Gaytan Medina\n",
    "\n",
    "An essential piece of analysis of large data is efficient summarization: computing aggregations like sum(), mean(), median(), min(), and max(), in which a single number gives insight into the nature of a potentially large dataset. In this section, we'll explore aggregations in Pandas, from simple operations akin to what we've seen on NumPy arrays, to more sophisticated operations based on the concept of a groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n",
    "\n",
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape\n",
    "(1035, 6)\n",
    "planets.head()\n",
    "method\tnumber\torbital_period\tmass\tdistance\tyear\n",
    "0\tRadial Velocity\t1\t269.300\t7.10\t77.40\t2006\n",
    "1\tRadial Velocity\t1\t874.774\t2.21\t56.95\t2008\n",
    "2\tRadial Velocity\t1\t763.000\t2.60\t19.84\t2011\n",
    "3\tRadial Velocity\t1\t326.030\t19.40\t110.62\t2007\n",
    "4\tRadial Velocity\t1\t516.220\t10.50\t119.47\t2009\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.rand(5))\n",
    "ser\n",
    "0    0.374540\n",
    "1    0.950714\n",
    "2    0.731994\n",
    "3    0.598658\n",
    "4    0.156019\n",
    "dtype: float64\n",
    "ser.sum()\n",
    "2.8119254917081569\n",
    "ser.mean()\n",
    "0.56238509834163142\n",
    "\n",
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "df\n",
    "A\tB\n",
    "0\t0.155995\t0.020584\n",
    "1\t0.058084\t0.969910\n",
    "2\t0.866176\t0.832443\n",
    "3\t0.601115\t0.212339\n",
    "4\t0.708073\t0.181825\n",
    "df.mean()\n",
    "A    0.477888\n",
    "B    0.443420\n",
    "dtype: float64\n",
    "\n",
    "df.mean(axis='columns')\n",
    "0    0.088290\n",
    "1    0.513997\n",
    "2    0.849309\n",
    "3    0.406727\n",
    "4    0.444949\n",
    "dtype: float64\n",
    "\n",
    "planets.dropna().describe()\n",
    "number\torbital_period\tmass\tdistance\tyear\n",
    "count\t498.00000\t498.000000\t498.000000\t498.000000\t498.000000\n",
    "mean\t1.73494\t835.778671\t2.509320\t52.068213\t2007.377510\n",
    "std\t1.17572\t1469.128259\t3.636274\t46.596041\t4.167284\n",
    "min\t1.00000\t1.328300\t0.003600\t1.350000\t1989.000000\n",
    "25%\t1.00000\t38.272250\t0.212500\t24.497500\t2005.000000\n",
    "50%\t1.00000\t357.000000\t1.245000\t39.940000\t2009.000000\n",
    "75%\t2.00000\t999.600000\t2.867500\t59.332500\t2011.000000\n",
    "max\t6.00000\t17337.500000\t25.000000\t354.000000\t2014.000000\n",
    "\n",
    "Aggregation\tDescription\n",
    "count()\tTotal number of items\n",
    "first(), last()\tFirst and last item\n",
    "mean(), median()\tMean and median\n",
    "min(), max()\tMinimum and maximum\n",
    "std(), var()\tStandard deviation and variance\n",
    "mad()\tMean absolute deviation\n",
    "prod()\tProduct of all items\n",
    "sum()\tSum of all items\n",
    "\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "df\n",
    "key\tdata\n",
    "0\tA\t0\n",
    "1\tB\t1\n",
    "2\tC\t2\n",
    "3\tA\t3\n",
    "4\tB\t4\n",
    "5\tC\t5\n",
    "\n",
    "df.groupby('key').sum()\n",
    "data\n",
    "key\t\n",
    "A\t3\n",
    "B\t5\n",
    "C\t7\n",
    "\n",
    "planets.groupby('method')\n",
    "\n",
    "planets.groupby('method')['orbital_period']\n",
    "\n",
    "planets.groupby('method')['orbital_period'].median()\n",
    "method\n",
    "Astrometry                         631.180000\n",
    "Eclipse Timing Variations         4343.500000\n",
    "Imaging                          27500.000000\n",
    "Microlensing                      3300.000000\n",
    "Orbital Brightness Modulation        0.342887\n",
    "Pulsar Timing                       66.541900\n",
    "Pulsation Timing Variations       1170.000000\n",
    "Radial Velocity                    360.200000\n",
    "Transit                              5.714932\n",
    "Transit Timing Variations           57.011000\n",
    "\n",
    "for (method, group) in planets.groupby('method'):\n",
    "    print(\"{0:30s} shape={1}\".format(method, group.shape))\n",
    "Astrometry                     shape=(2, 6)\n",
    "Eclipse Timing Variations      shape=(9, 6)\n",
    "Imaging                        shape=(38, 6)\n",
    "Microlensing                   shape=(23, 6)\n",
    "Orbital Brightness Modulation  shape=(3, 6)\n",
    "Pulsar Timing                  shape=(5, 6)\n",
    "Pulsation Timing Variations    shape=(1, 6)\n",
    "Radial Velocity                shape=(553, 6)\n",
    "Transit                        shape=(397, 6)\n",
    "Transit Timing Variations      shape=(4, 6)\n",
    "\n",
    "planets.groupby('method')['year'].describe().unstack()\n",
    "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
    "method\t\t\t\t\t\t\t\t\n",
    "Astrometry\t2.0\t2011.500000\t2.121320\t2010.0\t2010.75\t2011.5\t2012.25\t2013.0\n",
    "Eclipse Timing Variations\t9.0\t2010.000000\t1.414214\t2008.0\t2009.00\t2010.0\t2011.00\t2012.0\n",
    "Imaging\t38.0\t2009.131579\t2.781901\t2004.0\t2008.00\t2009.0\t2011.00\t2013.0\n",
    "Microlensing\t23.0\t2009.782609\t2.859697\t2004.0\t2008.00\t2010.0\t2012.00\t2013.0\n",
    "Orbital Brightness Modulation\t3.0\t2011.666667\t1.154701\t2011.0\t2011.00\t2011.0\t2012.00\t2013.0\n",
    "Pulsar Timing\t5.0\t1998.400000\t8.384510\t1992.0\t1992.00\t1994.0\t2003.00\t2011.0\n",
    "Pulsation Timing Variations\t1.0\t2007.000000\tNaN\t2007.0\t2007.00\t2007.0\t2007.00\t2007.0\n",
    "Radial Velocity\t553.0\t2007.518987\t4.249052\t1989.0\t2005.00\t2009.0\t2011.00\t2014.0\n",
    "Transit\t397.0\t2011.236776\t2.077867\t2002.0\t2010.00\t2012.0\t2013.00\t2014.0\n",
    "Transit Timing Variations\t4.0\t2012.500000\t1.290994\t2011.0\t2011.75\t2012.5\t2013.25\t2014.0\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0\t5\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "3\tA\t3\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "\n",
    "df.groupby('key').aggregate(['min', np.median, max])\n",
    "data1\tdata2\n",
    "min\tmedian\tmax\tmin\tmedian\tmax\n",
    "key\t\t\t\t\t\t\n",
    "A\t0\t1.5\t3\t3\t4.0\t5\n",
    "B\t1\t2.5\t4\t0\t3.5\t7\n",
    "C\t2\t3.5\t5\t3\t6.0\t9\n",
    "\n",
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})\n",
    "data1\tdata2\n",
    "key\t\t\n",
    "A\t0\t5\n",
    "B\t1\t7\n",
    "C\t2\t9\n",
    "\n",
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "display('df', \"df.groupby('key').std()\", \"df.groupby('key').filter(filter_func)\")\n",
    "df\n",
    "\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0\t5\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "3\tA\t3\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "df.groupby('key').std()\n",
    "\n",
    "data1\tdata2\n",
    "key\t\t\n",
    "A\t2.12132\t1.414214\n",
    "B\t2.12132\t4.949747\n",
    "C\t2.12132\t4.242641\n",
    "df.groupby('key').filter(filter_func)\n",
    "\n",
    "key\tdata1\tdata2\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "\n",
    "df.groupby('key').transform(lambda x: x - x.mean())\n",
    "data1\tdata2\n",
    "0\t-1.5\t1.0\n",
    "1\t-1.5\t-3.5\n",
    "2\t-1.5\t-3.0\n",
    "3\t1.5\t-1.0\n",
    "4\t1.5\t3.5\n",
    "5\t1.5\t3.0\n",
    "\n",
    "def norm_by_data2(x):\n",
    "    # x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x\n",
    "\n",
    "display('df', \"df.groupby('key').apply(norm_by_data2)\")\n",
    "df\n",
    "\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0\t5\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "3\tA\t3\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "df.groupby('key').apply(norm_by_data2)\n",
    "\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0.000000\t5\n",
    "1\tB\t0.142857\t0\n",
    "2\tC\t0.166667\t3\n",
    "3\tA\t0.375000\t3\n",
    "4\tB\t0.571429\t7\n",
    "5\tC\t0.416667\t9\n",
    "\n",
    "L = [0, 1, 0, 1, 2, 0]\n",
    "display('df', 'df.groupby(L).sum()')\n",
    "df\n",
    "\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0\t5\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "3\tA\t3\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "df.groupby(L).sum()\n",
    "\n",
    "data1\tdata2\n",
    "0\t7\t17\n",
    "1\t4\t3\n",
    "2\t4\t7\n",
    "\n",
    "display('df', \"df.groupby(df['key']).sum()\")\n",
    "df\n",
    "\n",
    "key\tdata1\tdata2\n",
    "0\tA\t0\t5\n",
    "1\tB\t1\t0\n",
    "2\tC\t2\t3\n",
    "3\tA\t3\t3\n",
    "4\tB\t4\t7\n",
    "5\tC\t5\t9\n",
    "df.groupby(df['key']).sum()\n",
    "\n",
    "data1\tdata2\n",
    "key\t\t\n",
    "A\t3\t8\n",
    "B\t5\t7\n",
    "C\t7\t12\n",
    "\n",
    "df2 = df.set_index('key')\n",
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "display('df2', 'df2.groupby(mapping).sum()')\n",
    "df2\n",
    "\n",
    "data1\tdata2\n",
    "key\t\t\n",
    "A\t0\t5\n",
    "B\t1\t0\n",
    "C\t2\t3\n",
    "A\t3\t3\n",
    "B\t4\t7\n",
    "C\t5\t9\n",
    "df2.groupby(mapping).sum()\n",
    "\n",
    "data1\tdata2\n",
    "consonant\t12\t19\n",
    "vowel\t3\t8\n",
    "\n",
    "display('df2', 'df2.groupby(str.lower).mean()')\n",
    "df2\n",
    "\n",
    "data1\tdata2\n",
    "key\t\t\n",
    "A\t0\t5\n",
    "B\t1\t0\n",
    "C\t2\t3\n",
    "A\t3\t3\n",
    "B\t4\t7\n",
    "C\t5\t9\n",
    "df2.groupby(str.lower).mean()\n",
    "\n",
    "data1\tdata2\n",
    "a\t1.5\t4.0\n",
    "b\t2.5\t3.5\n",
    "c\t3.5\t6.0\n",
    "\n",
    "df2.groupby([str.lower, mapping]).mean()\n",
    "data1\tdata2\n",
    "a\tvowel\t1.5\t4.0\n",
    "b\tconsonant\t2.5\t3.5\n",
    "c\tconsonant\t3.5\t6.0\n",
    "Grouping example\n",
    "\n",
    "decade = 10 * (planets['year'] // 10)\n",
    "decade = decade.astype(str) + 's'\n",
    "decade.name = 'decade'\n",
    "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)\n",
    "decade\t1980s\t1990s\t2000s\t2010s\n",
    "method\t\t\t\t\n",
    "Astrometry\t0.0\t0.0\t0.0\t2.0\n",
    "Eclipse Timing Variations\t0.0\t0.0\t5.0\t10.0\n",
    "Imaging\t0.0\t0.0\t29.0\t21.0\n",
    "Microlensing\t0.0\t0.0\t12.0\t15.0\n",
    "Orbital Brightness Modulation\t0.0\t0.0\t0.0\t5.0\n",
    "Pulsar Timing\t0.0\t9.0\t1.0\t1.0\n",
    "Pulsation Timing Variations\t0.0\t0.0\t1.0\t0.0\n",
    "Radial Velocity\t1.0\t52.0\t475.0\t424.0\n",
    "Transit\t0.0\t0.0\t64.0\t712.0\n",
    "Transit Timing Variations\t0.0\t0.0\t0.0\t9.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

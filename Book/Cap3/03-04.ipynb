{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d86f01-d8a0-4f38-909e-e7ebdb76df77",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "Eber David Gaytan Medina\n",
    "\n",
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous. In particular, many interesting datasets will have some amount of data missing. To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1\n",
    "array([1, None, 3, 4], dtype=object)\n",
    "\n",
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()\n",
    "dtype = object\n",
    "10 loops, best of 3: 78.2 ms per loop\n",
    "\n",
    "dtype = int\n",
    "100 loops, best of 3: 3.06 ms per loop\n",
    "\n",
    "\n",
    "vals1.sum()\n",
    "\n",
    "\n",
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype\n",
    "dtype('float64')\n",
    "1 + np.nan\n",
    "nan\n",
    "0 *  np.nan\n",
    "nan\n",
    "\n",
    "vals2.sum(), vals2.min(), vals2.max()\n",
    "(nan, nan, nan)\n",
    "\n",
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)\n",
    "(8.0, 1.0, 4.0)\n",
    "Keep in mind that NaN is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types.\n",
    "\n",
    "NaN and None in Pandas\n",
    "NaN and None both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:\n",
    "\n",
    "pd.Series([1, np.nan, 2, None])\n",
    "0    1.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3    NaN\n",
    "dtype: float64\n",
    "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present. For example, if we set a value in an integer array to np.nan, it will automatically be upcast to a floating-point type to accommodate the NA:\n",
    "\n",
    "x = pd.Series(range(2), dtype=int)\n",
    "x\n",
    "0    0\n",
    "1    1\n",
    "dtype: int64\n",
    "x[0] = None\n",
    "x\n",
    "0    NaN\n",
    "1    1.0\n",
    "dtype: float64\n",
    "\n",
    "Typeclass\tConversion When Storing NAs\tNA Sentinel Value\n",
    "floating\tNo change\tnp.nan\n",
    "object\tNo change\tNone or np.nan\n",
    "integer\tCast to float64\tnp.nan\n",
    "boolean\tCast to object\tNone or np.nan\n",
    "Keep in mind that in Pandas, string data is always stored with an object dtype.\n",
    "\n",
    "Operating on Null Values\n",
    "As we have seen, Pandas treats None and NaN as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:\n",
    "\n",
    "isnull(): Generate a boolean mask indicating missing values\n",
    "notnull(): Opposite of isnull()\n",
    "dropna(): Return a filtered version of the data\n",
    "fillna(): Return a copy of the data with missing values filled or imputed\n",
    "We will conclude this section with a brief exploration and demonstration of these routines.\n",
    "\n",
    "Detecting null values\n",
    "Pandas data structures have two useful methods for detecting null data: isnull() and notnull(). Either one will return a Boolean mask over the data. For example:\n",
    "\n",
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data.isnull()\n",
    "0    False\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "dtype: bool\n",
    "As mentioned in Data Indexing and Selection, Boolean masks can be used directly as a Series or DataFrame index:\n",
    "\n",
    "data[data.notnull()]\n",
    "0        1\n",
    "2    hello\n",
    "dtype: object\n",
    "The isnull() and notnull() methods produce similar Boolean results for DataFrames.\n",
    "\n",
    "Dropping null values\n",
    "In addition to the masking used before, there are the convenience methods, dropna() (which removes NA values) and fillna() (which fills in NA values). For a Series, the result is straightforward:\n",
    "\n",
    "data.dropna()\n",
    "0        1\n",
    "2    hello\n",
    "dtype: object\n",
    "For a DataFrame, there are more options. Consider the following DataFrame:\n",
    "\n",
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df\n",
    "0\t1\t2\n",
    "0\t1.0\tNaN\t2\n",
    "1\t2.0\t3.0\t5\n",
    "2\tNaN\t4.0\t6\n",
    "We cannot drop single values from a DataFrame; we can only drop full rows or full columns. Depending on the application, you might want one or the other, so dropna() gives a number of options for a DataFrame.\n",
    "\n",
    "By default, dropna() will drop all rows in which any null value is present:\n",
    "\n",
    "df.dropna()\n",
    "0\t1\t2\n",
    "1\t2.0\t3.0\t5\n",
    "Alternatively, you can drop NA values along a different axis; axis=1 drops all columns containing a null value:\n",
    "\n",
    "df.dropna(axis='columns')\n",
    "2\n",
    "0\t2\n",
    "1\t5\n",
    "2\t6\n",
    "But this drops some good data as well; you might rather be interested in dropping rows or columns with all NA values, or a majority of NA values. This can be specified through the how or thresh parameters, which allow fine control of the number of nulls to allow through.\n",
    "\n",
    "The default is how='any', such that any row or column (depending on the axis keyword) containing a null value will be dropped. You can also specify how='all', which will only drop rows/columns that are all null values:\n",
    "\n",
    "df[3] = np.nan\n",
    "df\n",
    "0\t1\t2\t3\n",
    "0\t1.0\tNaN\t2\tNaN\n",
    "1\t2.0\t3.0\t5\tNaN\n",
    "2\tNaN\t4.0\t6\tNaN\n",
    "df.dropna(axis='columns', how='all')\n",
    "0\t1\t2\n",
    "0\t1.0\tNaN\t2\n",
    "1\t2.0\t3.0\t5\n",
    "2\tNaN\t4.0\t6\n",
    "For finer-grained control, the thresh parameter lets you specify a minimum number of non-null values for the row/column to be kept:\n",
    "\n",
    "df.dropna(axis='rows', thresh=3)\n",
    "0\t1\t2\t3\n",
    "1\t2.0\t3.0\t5\tNaN\n",
    "Here the first and last row have been dropped, because they contain only two non-null values.\n",
    "\n",
    "Filling null values\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value. This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values. You could do this in-place using the isnull() method as a mask, but because it is such a common operation Pandas provides the fillna() method, which returns a copy of the array with the null values replaced.\n",
    "\n",
    "Consider the following Series:\n",
    "\n",
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data\n",
    "a    1.0\n",
    "b    NaN\n",
    "c    2.0\n",
    "d    NaN\n",
    "e    3.0\n",
    "dtype: float64\n",
    "We can fill NA entries with a single value, such as zero:\n",
    "\n",
    "data.fillna(0)\n",
    "a    1.0\n",
    "b    0.0\n",
    "c    2.0\n",
    "d    0.0\n",
    "e    3.0\n",
    "dtype: float64\n",
    "We can specify a forward-fill to propagate the previous value forward:\n",
    "\n",
    "# forward-fill\n",
    "data.fillna(method='ffill')\n",
    "a    1.0\n",
    "b    1.0\n",
    "c    2.0\n",
    "d    2.0\n",
    "e    3.0\n",
    "dtype: float64\n",
    "Or we can specify a back-fill to propagate the next values backward:\n",
    "\n",
    "# back-fill\n",
    "data.fillna(method='bfill')\n",
    "a    1.0\n",
    "b    2.0\n",
    "c    2.0\n",
    "d    3.0\n",
    "e    3.0\n",
    "dtype: float64\n",
    "For DataFrames, the options are similar, but we can also specify an axis along which the fills take place:\n",
    "\n",
    "df\n",
    "0\t1\t2\t3\n",
    "0\t1.0\tNaN\t2\tNaN\n",
    "1\t2.0\t3.0\t5\tNaN\n",
    "2\tNaN\t4.0\t6\tNaN\n",
    "df.fillna(method='ffill', axis=1)\n",
    "0\t1\t2\t3\n",
    "0\t1.0\t1.0\t2.0\t2.0\n",
    "1\t2.0\t3.0\t5.0\t5.0\n",
    "2\tNaN\t4.0\t6.0\t6.0\n",
    "Notice that if a previous value is not available during a forward fill, the NA value remains.\n",
    "\n",
    "< Operating on Data in Pandas | Contents | Hierarchical Indexing >\n",
    "\n",
    "Open in Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

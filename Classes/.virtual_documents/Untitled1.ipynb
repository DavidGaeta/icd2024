import pandas as pd
import re
import spacy as spc
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer





df = pd.read_csv(r'df_mini_HS.csv')


print(df)


df['text'] = df['text'].str.lower()
df['text'] = df['text'].str.replace(r"@\S+", "", regex=True)# Eliminar menciones a usuarios
df['text'] = df['text'].str.replace(r"http[s]?\://\S+", "", regex=True)# Eliminar enlaces
df['text'] = df['text'].str.replace(r"#\S+", "", regex=True)# Eliminar hashtags
df['text'] = df['text'].str.replace(r"[0-9]", "", regex=True)# Eliminar números
df['text'] = df['text'].str.replace(r"(\(.*\))|(\[.*\])", "", regex=True)# Eliminar paréntesis y corchetes
df['text'] = df['text'].str.replace(r"\n", "", regex=True)# Eliminar caracteres de nueva línea
df['text'] = df['text'].str.replace(r"(http[s]?\://\S+)|([\[\(].*[\)\]])|([#@]\S+)|\n", "", regex=True)# Eliminar varios patrones en una sola expresión regular (enlaces, paréntesis/corchetes, hashtags, menciones y nueva línea)
df['text'] = df['text'].str.replace(r"(\.)|(,)", "", regex=True)# Eliminar puntos y comas
df['text'] = df['text'].str.replace(r"[¡!]", "", regex=True)# Eliminar signos de admiración
df['text'] = df['text'].str.replace(r"[¿?]", "", regex=True) # Eliminar signos de exclamación


print(df["text"])


vectorizer = CountVectorizer()


df_v = vectorizado.fit_transform(df['text'])


df_vec = pd.DataFrame(df_v.toarray(), columns=vectorizado.get_feature_names_out())


X_bow_df['label'] = df['label'].values






